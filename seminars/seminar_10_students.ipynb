{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45a2b0-7c6c-452b-86e8-766fb0b4f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ba887-578d-4257-8de2-b209a3d01c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, layers_sizes, dropout_rate=0.1):\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for idx, s in enumerate(layers_sizes[:-1]):\n",
    "            if idx + 1 == len(layers_sizes) - 1:\n",
    "                layers.append(nn.Linear(s, layers_sizes[idx + 1]))\n",
    "            else:\n",
    "                layers.append(nn.Linear(s, layers_sizes[idx + 1]))\n",
    "                layers.append(..)\n",
    "                layers.append(nn.Dropout(p=dropout_rate))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9fcb5-cf33-4fdd-857c-f3a0b327a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if isinstance(model, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(model.weight)\n",
    "        if model.bias is not None:\n",
    "            nn.init.constant_(model.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661484c-ff97-4e5e-b9dd-99ebc1912925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b93d25-0ab5-4e31-b4e0-b1edeace020f",
   "metadata": {},
   "source": [
    "# 1. Аппроксимация прямой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adb41a-f623-41b4-90ce-557a0ccc0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, mean=0, std=1):\n",
    "    return 2 * x + 4 + np.random.normal(mean, std, size=x.shape)\n",
    "\n",
    "\n",
    "train_size = 100\n",
    "X_train = np.random.uniform(low=-2, high=2, size=train_size)\n",
    "y_train = foo(X_train, 0, 0)\n",
    "\n",
    "X_test = np.arange(-3, 3, 0.01)\n",
    "y_test = foo(X_test, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d69209-e2f1-4280-b706-2b322c087974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da008da-fb37-4118-97d4-571d88bdafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f0ce8-12da-44e0-af33-009a9148f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13709e73-7fea-4471-bbfc-a5c335b8353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5ae47-935b-41c2-8277-f043965b6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c464c4d-66d8-43ea-be5e-3bf81ebcd67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034ffe2-816e-4933-89a1-ef712e20295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [..]\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "dropout_rate = ..\n",
    "device = 'cpu'\n",
    "\n",
    "LR = ..\n",
    "STEP_SIZE = ..\n",
    "num_epochs = .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1c667-513d-4422-b47b-27bf113bed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_sizes = [input_size, *hidden_sizes, output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3c6cc-a609-4496-8599-2989423c9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultilayerPerceptron(layers_sizes, dropout_rate=dropout_rate)\n",
    "model.apply(initialize_weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353cf21-ab8d-4811-89aa-05816855ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = count_parameters(model)\n",
    "print(f\"Number of parameters: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6313ba-5aa8-444f-9a17-5123b0869e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=0.1)\n",
    "\n",
    "criterion = .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383b362-7ed8-460e-bd77-eeb18018f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, epoch_vis=10):\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        if epoch % epoch_vis == 0:\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Accumulate loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Average loss for this epoch\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            if epoch % epoch_vis == 0:\n",
    "                print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            # Save loss history for plotting\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "            else:\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "    # Plot train and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss_history, label='Train Loss')\n",
    "    plt.plot(val_loss_history, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model, train_loss_history, val_loss_history\n",
    "\n",
    "model_ft, train_loss, val_loss = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f233c7-f478-472c-9547-650360edb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_ft(X_test).squeeze().data\n",
    "plt.plot(X_test.squeeze(), y_pred)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f912e70-54d3-4894-8d47-ff2277708a73",
   "metadata": {},
   "source": [
    "# 2. Автодифференцирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4044dc7-035b-4b32-85f9-59c6a57939ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = 3 * a ** 3 - b ** 2\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0eaa6-24de-4f23-8704-8968488a9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)\n",
    "\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbbff3-49a9-4660-8538-5ce8b727f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultilayerPerceptron([2, 4, 1], dropout_rate=dropout_rate)\n",
    "model.apply(initialize_weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15577296-a147-4f9f-87ec-504b6e045876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f18774-863a-44cf-b8e6-9e34ca285873",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2)\n",
    "y = model(x)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9309e64-3db2-45e4-ad18-c5ab02b6eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# производная по параметрам\n",
    "model.network[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fc744-ddae-4bb7-94f1-904a8989f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# производная по входу\n",
    "x = torch.ones(2)\n",
    "x.requires_grad = True\n",
    "y = model(x)\n",
    "dV = torch.autograd.grad(y, x, grad_outputs=torch.ones(1, device=device), create_graph=True, retain_graph=True)[0]\n",
    "dV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8fb2c7-6ef3-4d87-bd88-a90fea83ba08",
   "metadata": {},
   "source": [
    "# 3. Взрыв и затухание градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11fb90-3817-4a39-a2fa-4b3730f38c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x : 1 / (1 + np.exp(-x))\n",
    "relu = lambda x : (x > 0).astype(float) * x\n",
    "\n",
    "weights = np.array([[1, 4], [4, 1]])\n",
    "activation = sigmoid(np.array([1, 0.01]))\n",
    "\n",
    "print(\"Activations\")\n",
    "activations = list()\n",
    "for iter in range(10):\n",
    "    activation = sigmoid(activation.dot(weights))\n",
    "    activations.append(activation)\n",
    "    print(activation)\n",
    "    \n",
    "print(\"\\nGradients\")\n",
    "gradient = np.ones_like(activation)\n",
    "for activation in reversed(activations):\n",
    "    gradient = (activation * (1 - activation) * gradient)\n",
    "    gradient = gradient.dot(weights.transpose())\n",
    "    print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d992a4-86be-4d09-899c-d5edcecd6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Relu Activations\")\n",
    "activations = list()\n",
    "for iter in range(10):\n",
    "    activation = relu(activation.dot(weights))\n",
    "    activations.append(activation)\n",
    "    print(activation)\n",
    "\n",
    "print(\"\\nRelu Gradients\")\n",
    "gradient = np.ones_like(activation)\n",
    "for activation in reversed(activations):\n",
    "    gradient = ((activation > 0) * gradient).dot(weights.transpose())\n",
    "    print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce474f76-146d-41fb-97ec-39d48519a790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
